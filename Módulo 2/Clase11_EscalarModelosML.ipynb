{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ¿Por qué escalar modelos de Machine Learning?\n",
    "\n",
    "https://www.codementor.io/blog/scaling-ml-6ruo1wykxf\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "- Al construir modelos de Machine Learning, nos enfocamos en datos, algoritmos y evaluación del rendimiento de los modelos.\n",
    "\n",
    "- Cuando ya hemos construido nuestros modelos y queremos usarlos en producción, en ese momento tenemos que cambiar nuestro enfoque: ingeniería de software y `DevOps`.\n",
    "\n",
    "![](https://i.pinimg.com/originals/a5/c3/64/a5c36433bca58823df513a212e854b89.jpg)\n",
    "\n",
    "- Hay varias cosas que debemos considerar a medida que pasamos del desarrollo a la producción con nuestros modelos de Machine Learning.\n",
    "\n",
    "    - **Deploying code to servers:** Tenemos que pensar en cómo vamos a implementar el código en nuestros servidores de producción.\n",
    "    - **Ensuring continuous availability:** También tenemos que darnos cuenta de que nuestros modelos deben estar disponibles continuamente. No podemos tenerlos abajo por largos períodos de tiempo.\n",
    "    - **Programmatic Access (APIs):** También debemos entender que no somos solo nosotros, los científicos de datos, quienes trabajamos con un modelo. Puede que ni siquiera sea un ser humano. Podría ser otra aplicación que está haciendo una llamada a nuestro modelo, por lo que queremos asegurarnos de que tenemos fácil acceso desde otros programas y, por lo general, lo hacemos mediante una interfaz de programación de aplicaciones o API.\n",
    "    - **Access Control:** Ahora, no queremos que sea demasiado accesible, queremos que solo los usuarios autorizados y las aplicaciones puedan usar nuestros modelos, por lo que queremos asegurarnos de tener controles de acceso en su lugar.\n",
    "    - **Scalability:** Y finalmente, queremos asegurarnos de que nuestros modelos sean escalables. Es decir, puede satisfacer las demandas que se le hacen para hacer predicciones.\n",
    "\n",
    "### Escalabilidad\n",
    "- Uno de los grandes avances tecnológicos de la última década es el avance en la investigación de los algoritmos de aprendizaje automático y el auge de sus aplicaciones.\n",
    "\n",
    "- Con frecuencia escuchamos sobre algoritmos de aprendizaje automático que realizan tareas del mundo real con una eficiencia similar a la humana (o, en algunos casos, incluso mejor).\n",
    "\n",
    "- Ya todos (deberían) saben el funcionamiento de varios algoritmos de aprendizaje automático y cómo implementarlos utilizando bibliotecas y marcos como  `sklearn`, `PyTorch`, `TensorFlow` y `Keras`, sin embargo hacerlo a escala es un juego más complicado.\n",
    "\n",
    "- Cada vez que vemos aplicaciones de aprendizaje automático, como:\n",
    "    - Traducción automática,\n",
    "    - Colorización de imágenes,\n",
    "    - Jugar juegos como Chess, Go e incluso DOTA-2,\n",
    "    - Generar caras reales,\n",
    "    - Generar imagenes a partir de texto ([Dall-e](https://openai.com/blog/dall-e/), [Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F) )\n",
    "    - Generación de texto a partir de texto (ChatGPT, Bard, Llama, Falcon)\n",
    "\n",
    "- Tales tareas requieren entrenar modelos en cantidades masivas de datos (más de cientos de GB) y una potencia de procesamiento muy alta (en chips especializados acelerados por hardware como `GPU` y `TPU`).\n",
    "\n",
    "- No podemos simplemente alimentar el conjunto de datos de `ImageNet` al modelo CNN que entrenamos en nuestra computadora portátil para reconocer los dígitos `MNIST` escritos a mano y esperar que brinde una precisión decente después de unas pocas horas de entrenamiento.\n",
    "\n",
    "- El aprendizaje automático ha existido durante años, pero a la velocidad a la que se están produciendo los desarrollos en el aprendizaje automático y los campos asociados, la escalabilidad se está convirtiendo en un tema destacado de atención.\n",
    "\n",
    "### La difusión de internet\n",
    "\n",
    "- Internet ha estado llegando a las masas, las velocidades de la red están aumentando exponencialmente y la huella de datos de un \"ciudadano de Internet\" promedio también está aumentando, lo que significa más datos para que los algoritmos aprendan.\n",
    "- Los productos relacionados con el Internet de las cosas están listos para obtener una adopción masiva y, eventualmente, brindarnos más datos para que los aprovechemos.\n",
    "\n",
    "### Auge del hardware\n",
    "\n",
    "- Debido a mejores técnicas de fabricación y avances tecnológicos, el almacenamiento es cada vez más económico.\n",
    "- [La ley de Moore](https://es.wikipedia.org/wiki/Ley_de_Moore) se mantuvo durante varios años, aunque ahora se ha ralentizado.\n",
    "- La eficiencia y el rendimiento de los procesadores han crecido a un buen ritmo, lo que nos permite realizar tareas de computación intensivas a bajo costo.\n",
    "\n",
    "### Auge de DevOps\n",
    "\n",
    "- La última década no solo ha sido sobre el auge de los algoritmos de aprendizaje automático, sino también el auge de la creación de contenedores, los marcos de orquestación y todas las demás cosas que facilitan la organización de un conjunto distribuido de máquinas.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## 2. ¿Por qué importa la escalabilidad?\n",
    "\n",
    "La escalabilidad es importante en Machine Learning porque:\n",
    "\n",
    "- Entrenar a un modelo puede llevar mucho tiempo.\n",
    "- Un modelo puede ser tan grande que no cabe en la memoria de trabajo del dispositivo de entrenamiento.\n",
    "- Incluso si decidimos comprar una máquina grande con mucha memoria y potencia de procesamiento, de alguna manera será más costosa que usar muchas máquinas más pequeñas. En otras palabras, el escalamiento vertical es costoso.\n",
    "\n",
    "La escalabilidad se trata de manejar grandes cantidades de datos y realizar muchos cálculos de una manera rentable y que ahorra tiempo. Estos son los beneficios inherentes de preocuparse por la escala:\n",
    "\n",
    "### Productividad:\n",
    "- Una gran parte del aprendizaje automático en estos días ocurre en forma de experimentos, como resolver un problema novedoso con una arquitectura novedosa (algoritmo).\n",
    "- Un pipeline con ejecuciones rápidas de cada etapa (capacitación, evaluación e implementaciones) nos permitirá probar más cosas y ser más creativos.\n",
    "\n",
    "### Modularidad, portabilidad y composición:\n",
    "- Sería beneficioso si los resultados del entrenamiento y el modelo entrenado pudieran ser aprovechados por otros equipos.\n",
    "\n",
    "### Reducción de costes:\n",
    "- Nunca está de más optimizar los costes.\n",
    "- El escalado ayuda a utilizar los recursos disponibles al máximo y hace un balance entre el costo marginal y la precisión.\n",
    "\n",
    "### Minimizar la participación humana:\n",
    "- El pipeline debe estar lo más automatizada posible para que los humanos puedan salir y disfrutar del café mientras las máquinas hacen su trabajo.\n",
    "\n",
    "\n",
    "### Ejemplos en la industria\n",
    "- El 25 % de los ingenieros de Facebook trabajan en el entrenamiento de modelos, entrenando 600K modelos al mes.\n",
    "- Su servicio de predicción en línea hace 6 millones de predicciones por segundo.\n",
    "- El entrenamiento del modelo de búsqueda profunda de Baidu (google de china) implica una potencia informática de 250 TFLOP/s en un grupo de 128 GPU.\n",
    "- Así que podemos imaginar lo importante que es para esas empresas escalar de manera eficiente y por qué la escalabilidad en el aprendizaje automático es importante en estos días.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vamos a explorar cuáles son las áreas en las que debemos centrarnos para que nuestro flujo de aprendizaje automático sea escalable. Primero, repasemos el proceso típico.\n",
    "\n",
    "## 3. El proceso de Machine Learning\n",
    "\n",
    "Para comprender mejor las oportunidades de **escalar**, repasemos rápidamente los pasos generales involucrados en un proceso típico de machine Learning:\n",
    "\n",
    "### 3.1. Comprensión del dominio (de negocio)\n",
    "\n",
    "- El primer paso suele ser obtener una comprensión profunda del problema y su dominio.\n",
    "- En este paso, consideramos las restricciones del problema, pensamos en las entradas y salidas de la solución que estamos tratando de desarrollar y cómo la empresa interpretará los resultados.\n",
    "\n",
    "### 3.2. Recopilación y almacenamiento de datos\n",
    "\n",
    "- El siguiente paso es recopilar y preservar los datos relevantes para nuestro problema.\n",
    "- La cantidad de datos que necesitamos depende del problema que estamos tratando de resolver.\n",
    "- Por ejemplo, entrenar un clasificador de imágenes general en miles de categorías necesitará una gran cantidad de datos de imágenes etiquetadas (al igual que `ImageNet`).\n",
    "\n",
    "### 3.3. Análisis de datos exploratorios e ingeniería de características\n",
    "\n",
    "- El siguiente paso generalmente es realizar un análisis estadístico de los datos, manejar los valores atípicos, manejar los valores faltantes y eliminar las características altamente correlacionadas del subconjunto de datos que estaremos alimentando a nuestro algoritmo de aprendizaje automático (Control de calidad de los datos).\n",
    "- Generación de nuevas características\n",
    "\n",
    "### 3.4. Modelado (entrenamiento)\n",
    "\n",
    "- Ahora viene la parte en la que entrenamos un modelo de aprendizaje automático con los datos preparados.\n",
    "- Dependiendo de la declaración de nuestro problema y de los datos que tengamos, es posible que tengamos que probar un montón de algoritmos y arquitecturas de entrenamiento para descubrir cuál se adapta mejor a nuestro caso de uso.\n",
    "\n",
    "### 3.5. Evaluación (Test)\n",
    "\n",
    "- Es hora de evaluar el rendimiento del modelo.\n",
    "- Por lo general, tenemos que ir y venir entre el modelado y la evaluación varias veces (después de ajustar los modelos) antes de obtener el rendimiento deseado para un modelo.\n",
    "\n",
    "### 3.6. Implementación (inferencia)\n",
    "\n",
    "Finalmente, preparamos nuestro modelo entrenado para el mundo real. Es posible que queramos integrar nuestro modelo en el software existente o crear una interfaz para usar su inferencia.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Desafíos del escalamiento\n",
    "\n",
    "Bien, ahora enumeremos algunas áreas de enfoque para escalar en varias etapas en varios procesos de Machine Learning.\n",
    "\n",
    "\n",
    "### 4.1. Manejo de datos\n",
    "\n",
    "- Los datos se alimentan iterativamente al algoritmo de entrenamiento durante el entrenamiento, por lo que la representación en la memoria y la forma en que los alimentamos al algoritmo jugarán un papel crucial en el escalado.\n",
    "- El viaje de los datos, desde la fuente hasta el procesador, para realizar cálculos para el modelo puede tener muchas oportunidades para que optimicemos.\n",
    "\n",
    "### 4.2 Entrenamiento modelo\n",
    "\n",
    "- El entrenamiento de modelos consiste en una serie de cálculos matemáticos que se aplican a datos diferentes (o iguales) una y otra vez.\n",
    "- Esta naturaleza iterativa se puede aprovechar para paralelizar el proceso de entrenamiento y, finalmente, reducir el tiempo requerido para el entrenamiento mediante la implementación de más recursos.\n",
    "- Sin embargo, el simple despliegue de más recursos no es un enfoque rentable.\n",
    "- También debemos centrarnos en mejorar el poder de cómputo de los recursos individuales, lo que significa unidades de procesamiento más rápidas y pequeñas que las existentes.\n",
    "- Centrándonos en la investigación de algoritmos más nuevos que sean más eficientes que los existentes, podemos reducir la cantidad de iteraciones necesarias para lograr el mismo rendimiento y, por lo tanto, mejorar la escalabilidad.\n",
    "- También podemos intentar reducir la huella de memoria del entrenamiento de nuestro modelo para una mejor eficiencia.\n",
    "- Además, existen algunas preguntas para responder:\n",
    "    - ¿Valen la pena las capas extra de `X`?\n",
    "    - ¿Una cantidad `Y` adicional de datos realmente mejora el rendimiento del modelo?\n",
    "    - ¿Cuándo debemos dejar de entrenar?\n",
    "\n",
    "### 4.3. Evaluación, experimentación y despliegue\n",
    "\n",
    "- Además de poder calcular métricas de rendimiento, deberíamos tener una estrategia y un marco para probar diferentes modelos y descubrir `hiperparámetros` óptimos con menos esfuerzo manual.\n",
    "- Los modelos que implementamos pueden tener diferentes casos de uso y patrones de uso.\n",
    "- Nuestros sistemas deberían poder escalar sin esfuerzo con las demandas cambiantes de la inferencia del modelo.\n",
    "\n",
    "![](mlops.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Conceptos de escalamiento de Machine Learning para producción\n",
    "\n",
    "VIDEO PARA QUE NO SE DUERMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Cómo escalar los modelos?\n",
    "\n",
    "- Del video anterior ya aprendimos que correr modelos de Machine Learning en `clusters` de servidores tiene sus ventajas cuando queremos desplegar un sistema escalable y con alta disponibilidad.\n",
    "- Pero, ¿cómo implementamos nuestros modelos en estas múltiples máquinas, especialmente cuando agregamos y eliminamos servidores según la demanda?\n",
    "\n",
    "### Microservicios\n",
    "\n",
    "- Desplegar el modelo con una API\n",
    "- Correr el modelo y la API en un contenedor (Docker)\n",
    "- Gestionar los contenedores en el clúster mediante un servicio de orquestación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T01:43:02.654183Z",
     "start_time": "2023-09-21T01:43:02.611120Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
